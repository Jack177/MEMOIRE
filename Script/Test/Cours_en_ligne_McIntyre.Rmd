---
title: "Bryce Canyon"
author: "Jordan"
date: "`r Sys.Date()`"
output: html_document
---

```{r library, include=FALSE}
library("readxl")
library(dplyr)
library(tidyverse)
library(knitr)
library(ggplot2)
library(labdsv)
library(ggthemes)
```

Vidéo de Nancy McIntyre

/!\\ plot peut signifier terrain/site !!!
/!\\ occurence signifie la presence sur différents lieux => distribution !!!
# Site X Species 
https://www.youtube.com/watch?v=fftppBYyexE
## Importation

Importation d'un tableau de 169 sp de plantes (colonne) x 160 sites.
Les colonnes ont pour valeur la couverture des sites par les sp de plantes, modalité entre  0.2 et 6.0 (variable qualitative ordinale).
Plus d'info : https://www.rdocumentation.org/packages/labdsv/versions/2.0-1/topics/bryceveg

## Première question : abondance des sp
Dans combien de sites chaque sp est présentes ?
Original question: "In how many plots does each species occur?"

La réponse doit donner le nombre d'occurence (individus) pour les sites.

Un graphique d'accumulation peut donner cette information en donnant sur l'axe de y le nombre de site et en x le nombre d'espèces.
```{r bryceveg plot cumulative}
# Lien vers les fichiers
# myweb.ttu.edu/nmcintyr/Stat_Analysis_Ecol_Communities/SAEC.html

data(bryceveg)
data(brycesite)
# Besoin de faire ça pour avoir un bon format
veg <- bryceveg
site <- brycesite

# 
spc.pres <- apply(veg>0,2,sum) # on garde que les valeurs positives; "2" indique colonnes; somme les individus par sp

# Courbe d'accumulation des espèces 
plot(sort(spc.pres))

```

On obtient une courbe d'accumulation, il faut environ 100 sites pour les 169 sp.

Si on linéarise la courbe, on peut obtenir plus d'information.

Le second graphique a une échelle différente, log sur la préscence actuelle des sp (= abondance des sp).
Le premier graphique est plus approprié. Il garde l'échelle original, ce qui rend l'intrepréation plus facile.
Environ 100 des 169 sp sont trouvé sur 10 sites, ce qui signifie qu'un grand nombre d'espèce est rare, peu sont abondantes.



```{r bryceveg plot cumulative log}
# Linearisation de la courbe 
plot(sort(spc.pres), log = 'y',
     main = "Cumulative Distribution of Species Occurrences",
     xlab = "Cumulative Count of Species", ylab = "Number of Plots")
# Mauvais graph
plot(sort(log(spc.pres)),
     main = "Cumulative Distribution of Species Occurrences",
     xlab = "Cumulative Count of Species", ylab = "")
```

## Question 2 : couverture 

Quelle est la couverture moyenne de chaque espèce lorsqu'elle est présente (sans compter les 0 pour les sites où elle est absente) ?
What is the mean cover of each species when it occurs (not including 0s for plots where it is absent)?


On va se concentrer sur l'abondance mesurée en pourcentage de couverture dans chaque site.

On calcule les sommes des colonnes de la matrice veg.

Le graphique de la distribution de l'abondance des espèces est encore plus asymétrique, cela signifie que la plupart des espèces sont présentes a de très faibles abondances. La plupart ont moins de 5 % de couverture, seulement qq sp sont abondantes.
La plupart des sp ont une abondance faible.
```{r cover}
# normalement "cover" est à la place de "veg", dans la vidéo YT le code n'est pas donné
tmp <- apply(veg,2,sum)
spc.mean <- tmp/spc.pres

# 
plot(sort(spc.mean), log = 'y',
     main = "Cumulative Species Abundance Distribution",
     xlab = "Cumulative Number of Species", ylab = "Mean Abundance")

```
## Question 3 : abondance corrélé avec le nombre de site ?
L'abondance moyenne des espèces est-elle corrélée au nombre de sites dans lesquelles elle est présente ?
Original: "Is the mean abundance of species correlated with the number of plots in which it occurs?"

En bas à droite du graphique ont une abondance très faible.
Le point en haut à droite indique une espèce répandue et abondante.
Les deux pointes en haut à gauche : montre qu'ils sont abondant si présent.

Réponse : non, il n'y a pas de corrélation entre l'abondance moyenne et la présence dans les sites.
```{r abondance et prescence}

plot(spc.pres,spc.mean)
identify(spc.pres,spc.mean, names(veg))

```

## Question : Combien d'espèce sont présent sur chaque site ?

Il y a 3 à 27 sur 169 espèces  par site.
```{r sp by site}
# On aurait du mettre la variable "cover", mais elle n'est pas expliqué
# Le graphique resemble malgré tout
#plt.pres <- apply(cover>0, 1,sum)
plt.pres <- apply(veg>0, 1,sum)
plot(sort(plt.pres))

```

## Question : L'abondance totale de la végétation est-elle corrélée au nombre d'espèces présentes dans une parcelle ?

Original: "Is the total abundance of vegetation correlated with the number of species in a plot?"

Il y a 3 à 27 sur 169 espèces  par site.
```{r abundance corr. nbr sp by site}

# On aurait du mettre la variable "cover", mais elle n'est pas expliqué
# Le graphique resemble pas trop
#plt.sum <- apply(cover,1,sum)
plt.sum <- apply(veg,1,sum)

plot(sort(plt.sum))
plot(plt.pres,plt.sum)
```

#  Site x env

## Exploration site x env

On voit qu'il n'y a aucun patern, pas de tendance, ces variables ne sont pas corrélés entre elles.
On pourrait parler de shotgun data.

La fonction cor() donne une corrélation de Pearson qui va de 1 à -1. Il indique la force et la direction entre 2 variables.
0.09244026 : il n'y a pas de corrélation.
Par défaut, Pearson est utilisé, c'est une version paramétrique qui suppose une relation linéaire entre des variables continues. 
La corrélation de Spearman est l'équivalent non-paramétrique, il utilise des rangs et peut-être utilise pour des variables qualitatives ordinales. 
Il ne suppose pas de linéarité. Il relâche ces suppositions mais en contrepartie il est moins puissant statistiquement. 
Spearman indique également qu'il n'y a pas de corrélation.

```{r explo 1}
attach(site)

plot(av,elev)
cor(av, elev)
cor(av, elev, method = "spearman")

```

Le chevauchement de ces boîtes indique qu'il n'y a pas de corrélation entre eux.
Il n'est pas possible d'utiliser la fonction cor(), celle-ci a besoin de données numériques.
Le deuxième graph utilise deux variables catégorielles/nominale
```{r explo 2}
plot(depth, asp, ylab="aspect in degrees")
plot(depth,pos)
```
Toujours pas de pattern ici.

```{r explo 3}
# Mettre des graph par 2
par(mfcol=c(1,2))

plot(elev[depth=='deep'],av[depth=='deep'])
plot(elev[depth!='deep'],av[depth!='deep'])
```




Peu de chevauchement, faut faire un t-test pour savoir s'il y a une différence significative.
La p-value indique que les "deep soils" ne sont pas présent à la même moyenne d'élévation "shallow". Ecologiquement cela fait sens.
Le test équivalent non-paramétrique d'un t-test
Les conditions des tests non paramétriques sont plus facile à satisfaire, mais perde beaucoup en puissance.

```{r explo 4}

plot(depth,elev)
#plot(elev,depth)

t.test(elev~depth,var.equal=FALSE) # on suppose pas que la variance est la même dans les données des 2 boîte
```

# Pattern in community data
https://www.youtube.com/watch?v=oZsaNU-YXCw

Deux propriétés des espèces stimule les patterns de biodiversités
Occurence (distribution/répartition) et Abondance
Ces deux facteurs définissent la biodiversité.
Ensemble ils génèrent des patterns :
- La plupart des espèces sont rare; peu sont communes
- La plupart des communautés contiennent seulement un sous-ensemble des espèces présent dans cette région. Ce n'est pas parce qu'une espèce est présente dans une région qu'elle sera présente dans n'importe quelle communauté pour une variété de raisons (partages/limitations des ressources, limitation de la dispersion, biotique intéraction ou chance). Ce qu'on observe est alors ce qui pourrait être présent.
- Les espèces communes tend à avoir une large distribution, tandis que les espèces rares ont une distributions plus faible. Une relation positive entre l'abondance et la présence.
- Les communautés qui ont une grande richesse ont tendance a avoir une abondance globale. Càd, que des sites avec une grande richesse ont également beaucoup d'individus présent.

Des patterns peuvent également apparaître dû à l'échantillonnage et non pas à la nature.
La plus connue est que la richesse est positivement associé avec le nombre d'échantillon collecté (= effort de collecte).
Si on retrouve ces patterns, ont doit essayer de savoir pourquoi on les as. Cela peut-être dû a des erreurs d'encodage/transcription, dû a une faible taille  d'échantillonnage ou quelques choses de réél et d'étrange qui serait important de savoir.

Il y a de la rareté de l'abondance et de l'occurrence. La rareté est commune, les sp communes sont rares dans l'écologie des communautés.


## Abondance et occurence
Le premier graphique classe les sp les plus fréquemment rencontrées à celle trouvés sur un seul site (en bas à droite du graph). On remarque que peu d'espèces sont abondantes et bcp sont rares. 


Note : sur YT le 2ème graphiques est différents. 

Le deuxième graphique ici, montre peu de site ont une richesse très faible et peu de site ont une richesse très élevé, la plupart ont une richesse plus ou moins élevé.

Note : sur YT le 4ème graphiques est différents. 

Le troisième graphique ici, les sp rares (~faible abondance) ont été retrouvé sur peu de sites.
Il y a une corrélation positive entre l'occurence et l'abondance si on fait une régression linéaire on aurait une droite.
Avec les espèces les plus abondantes ayant la plus grandes distributions et l'inverse pour les sp rares.

Le quatrième graphique ici (x= richesse, y= abondance totale), montre que plus un site possède de richesse plus il possède d'abondance des sp

Ces graphiques montrent des patterns régulièrement observés dans les jeux de données des communautés.
```{r}
# abundance and occurence
abuocc(veg)
```


# Indice de biodiversité
https://www.youtube.com/watch?v=7eXgEwbERVs

Rappel : 
_occurence_ (répartition) caractérise la distribution d'une espèce.
_abundance_ (abondance) caractérise le nombre d'organisme d'une espèce par unité d'espace.
_incidence or occurrence_ est parfois utilisé pour présence/abscence

La richesse est souvent noté S.
Les méthodes pour caractériser la biodiversité dépend du jeux de données.
Si on a beaucoup de 0 ou pas.

On distingue deux types de méthodes:
Abundance based measure : dans le cas où l'on a compté les individus de plusieurs espèces et l'on peut avoir confiance en ces chiffres.
Incidence-based measure : dans le cas où l'on a des données de types présence-absence ou si le comptage n'a pas pu être précis.
(Exemple : brin d'herbe d'une graminé ou nuée d'oiseaux).


Abundance based measure 
Chao1
ACE
other

Incidence-based measure
Chao2
Ice
Jacknife 1st order
Jacknife 2nd order
Bootstrap
other


Chao1 et Chao2 sont utile si on a beaucoup de singletons ou doubletons.
singleton = espèce représenté par un seul individus.
doubleton = espèce représenté par deux individus.
Chao1 et Chao2 on tendance a sous-estimé la richesse réelle présente dans une communauté.

Jacknife 1 et2 peut surestimer ou sous-estimé la richesse. Ces indices donnent souvent une valeur plus grande que le nombre d'espèce observées.
L'hypothèse est que le nombre d'espèce observé est plus petite que le nombre d'espèce rééllement présent.
Mais Jacknife peut donner des valeurs inférieures que la richesse observée, évidemment ces nombres sont faux.
C'est problèmatique notamment si on a beaucoup de zéros dans le jeux de données.

La méthode du bootstrap a une limitation similaire, si on a beaucoup de zéro, si on a une matrice peu dense, bien que cet indice soit moins enclin a surestimer la richesse.
Dans le livre de 2003 "Measuring Biological Diversity", l'auteur résume les performances de ces indices.
Il n'y a pas de consensus pour savoir lequel est le meilleur. Conseil utiliser plusieurs indices et utiliser le résultat consensuel

Sur la vidéo elle montre des graphiques avec chacun des estimateurs.
S est calculé avec specpool, ce sont les données enregistrées, ensuite chao2, jacknife 1 et 2 et bootstrap. Avec 95% de CI. Basé sur la taille de l'échantillon (=le nombre de sites), car ce sont des Incidence-based measure.
Avec ces graphiques on voit quelle indice ont un comportement étrange (chao2). Chao2 surestime bizarrement la richesse.


Si on a des indices d'Abundance based measure, encore une fois il est important de mettre en graphique les indices et de les comparer. On a la mesure et le 95 CI.
Les deux indices présentés on des CI plus larges à faible taille d'échantillonnage et à l'opposé à grande taille d'échantillonnage.
Ceci suggère qu'évaluer la richesse avec un faible échantillonnage est imprécis

## Diversité
Diversity index (or diversty metric)
Pour deux communautés différentes ayant le même nombre d'espèce différentes (S = richesse) et le même nombre d'individus (N). On peut clairement voir une différence de diversité dans l'exemple.

Les indices de biodiversité peuvent permettre de caractériser cette distinction. Le problème des indices de diversité, c'est qu'ils utilisent la richesse et _evenness_ (=distribution ?) qui peuvent avoir différentes pressions écologique et formes de sélection évolutives. Ces indices les combinent en un seul nombre.
La simplicité de l'indice de diversité est sa force tout comme sa principale faiblesse.

L'indice le plus populaire est celui de Shannon-Wiener H'.
Il est très sensible à la taille de l'échantillon et très influencé par la rareté. De plus, il peut être difficile à interpréter.

Indice de Simpson's Lambda, son inverse et D = 1 - lambda
Fischer alpha : pas sensible à la taille de l'échantillon si la taille est supérieur a 1000.
Et suppose que les données suivent un distribution normal log, ce qui n'est pas toujours le cas.
Il a plein de problèmes.

Chaque indices a ses utilités et ses problèmes/défauts.

Le problèmes de ces indices est qu'il n'y a pas d'unité, ce qui les rends difficile à interprétêr et de les comparer, et donc d'avoir un consensus.
On sait juste dire quelle communauté est plus diversifié qu'une autre.


## Evenness

Indice
Pielou J : appellé aussi the Shannon evenness index, est très utilisé, mais a les mêmes limitations que Shannon car il est basé dessus.
Evenness = équitabilité

## Problèmes avec indices de richesse, diversité et evenness
On a toujours des nombres, les indices ne prennent pas en compte l'identité des espèces !
Comme les espèces invasives, exotiques ou menacées.
Si on ne fait attention seulement à la mesure de la diversité quantitative, on peut ne pas différencier deux communautées qui diffère profondémment dans ces services écosystèmiques qu'ils fournissent. Car les espèces exotiques/invasives qui remplace une espèce native.
Les chiffres ne distinguent pas les espèces établies, migratoires ou en transit, les accidents. Ces indices ne prennent pas cela en compte.

Si on a des réplicats c'est bénéfique si on a de multiples réplicats. On peut faire la moyenne. On peut avoir une sorte de moyenne consensus.

Certains indices accentue les espèces rares ou abondantes, ou ont des conditions à respecté.

# Note : les limites des indices de diversité et autres sont données ici :
https://ericmarcon.github.io/MesuresBioDiv2/sec-conclusionSynthese.html#entropie-et-diversit%C3%A9-1

Conseil
1) Examiner nos objectives.
Est-ce qu'on est intéressé par la richesse ou juste l'abondance ou evenness ou tout ?

2) Examiner le jeux de données
Abundance based measure ou Incidence based measure  data, est-ce qu'il y a beaucoup de zéros ?

3) Utiliser de multiples indices appropriés et regarder pour un consensus.
Si un indice donne un avis contraire au consensus, on devrait investiguer cet indice un peu plus.
Probalement que les données violent les conditions pour cette indices. 
Si il n'y a pas de tendances consitantes qui se dessine cela justifie plus d'investigations.


## Scales of diversity (échelle de diversité)
Le résultat de la diversité local est dû à la réponse des organismes aux conditions locales.
La diversité biogéographique est dû à la spéciation.
Il est important de savoir à quelle échelle de diversité on s'intéresse et de quoi on parle.

Diversité alpha, béta, gamma, epsilon
alpha = diversité locale d'un habitat (indice utilisé précédemment)

(info beta interpretation: https://www.bonobosworld.org/fr/glossaire/diversite-beta )

beta (= turnover diversity) = diversité entre habitats ou patch(= parcelle) elle représente la mesure dans laquelle la composition des espèces varie par localisation/habitat. Il est influencé par l'échelle (distance), il décroit à mesure que la superficie ou le temps d'échantillonage augmente.
Les valeurs relatives de beta indique une diversité faible, cela revient à dire qu'il y a peu de similarité de communauté, avoir un beta de 0 indique qu'il y a un
chevauchement total entre les habitats, pas de turnover
Beta indique les espèces partagé entre ces patch, si certains sont unique pour chacun d'entre eux
gamma = diversité du paysage (diversité d'une région avec une multitude de types d'habitat)
epsilon = diversité province biogéographique ou biome

### Exercice

Richness
pck vegan
specpoll poolaccum => incidence data
estimateR() estaccumR() => abundance data

Diversity
pck vegan
diversity()
pck plyr
pck BiodiversityR
diversitycom() => Error => StringsAsFactors()
diversityresult()

Eveness
pck BiodiversityR
diversitycom() => Error => StringsAsFactors()
diversityresult()

Scales of diversity
GBbiol.csv, GBsite.csv
pck vegan
specpoo()
betadiver() => 24 similarity (dissimilarity) indice
4 dissimillarités recommandés : w whitaker, j jacquard, sor sorensen, sim similiraty
analyse de similarité : anosim() ; ressemble à une analyse de la variance mais avec la similarité à la place
anosim suppose une égalité de la variance des groupes, cependant c'est seulement permis pour les modèles simples à une variable sans effets d'intéractions et
ne peut être utilisé seulement pour variable catégorique pas pour des variables continues.
Anosim a beaucoup de limitations
Alternative : permanova

Exemple anosim:
gb.b <- betadiver(gb.biol, method = "w)
gb.ano <- anosim(gb.b, gb.site$Habitat)

Le graph montre que la dissimilarité entre les groupes est plus importantes que les dissimilarités intra groupe

Question à répondre
1) Cmb d'sp ont été trouvé
2) Cmb d'espèces ont été trouvé pour chaque site ? Quel habitat a le plus d'espèce ?
3) Quelle indicateur de richess donne la "meilleure" approximation de la richesse observées ?
4) Quel type d'habitat est le plus diversifié ? Quel en a le moins ? 
5) Quel type d'habitat été le plus 'envenly distributed' (distribué homogènement?) parmi les espèces?
6) Quel est l'echelle du paysage de la richesse des sp abeilles ?
7) Quel habitat a la plus grande diversité alpha ?
8) Quels sites ont la composition d'espèces la plus similaire ?
Bonus : Y avait-il des sites aberrants en ce qui concerne les espèces d'abeilles ?




### Species abundance
https://www.youtube.com/watch?v=awN2ks75AP0
Hypothèse tacite
- Toute les espèces sont détectables équitablement (la taille des WB influencent la capture)
- Toutes les espèces sont echantillonné sur à la même échelle

La météo d'un jour à l'autre peut influencer l'abondance.
Quand on compare deux communautés on doit standariser l'abondance (à cause des artéfacts d'échantillonnage)
=> raréfaction = déterminer nbr individus dans le plus petit échantillonnage et tirer au hasard ce nbr dans les échantillons plus grand pour estimer le nombre d'espèces attendus si on sample le plus petit nbr d'individus

Le pattern le plus commun : la plupart des espèces sont rares et il y a peu d'espèce communes, ce qui signifie que peu d'espèces ont le plus d'individus dans une communauté

Rank-abundance curve (=dominance diversity plot)
axe des x : rang avec les sp avec ordre décroissant d'abondance (Bombus 1er, singleton dernier)
axe des y : abondance de chaque sp
Plus la pente est faible, plus la communauté est homogène, si la courbe est plate, c'est qu'il y a le même nombre d'individus pour chaque espèces (extrêmement rare)
Généralement, la courbe a une pente négative avec différentes formes, ce qui montre un déséquilibre dans la distribution de l'abondance.
Il existe deux dizaines de formes que la distribution peut prendre, chacun résultant d'un processus différent qui peut être modéler mathématiquement.
Vagan a 5 des plus commune.
1) Null model= modele broken stick




# Cluster analysis
https://www.youtube.com/watch?v=Y-ZGHA2GZ3g
Utilisé pour divisé les données en clusters non superposés

Hierarchical vs non-hierarchical(disjoint)  
  hierarchical - agglomerative vs divisive
    agglomerative - single, complete, average linkiage
  Disjoint - k-means

Disjoint est utilisé si on a un à priori sur le nombre de cluster que l'on devrait avoir.
Si on ne sais pas => hierarchical
hierarchical peut être utilisé sur différent types de dissimilarité ou distance métrique
Disjoint sont moins sensible aux outliers (= données abérantes) et sont utile pour les détecter.

Il faut savoir quelle type de matrice de distance ou matrice dissimilarité on souhaite évaluer et également ce que l'on souhaite faire.
Si on veut détecter les outliers, la puissance de calcul de notre ordinateur (important si bcp de données).


## Hierarchical - agglomerative vs divisive
On base le clustering sur la similarité (agglomerative) ou sur la distinction 

agnes() vs diana()

### Agglomerative
Plus commun en écologie car bon pour identifié les petits clusters
Output : les deux sites les plus similaires ou dissimilaires sont fusionné dans un noeud qui représente un cluster.
Un axe (heigh ou dissimilarity) plus l'axe est haut moins les objets sont similaires. La proximité horizontal ne donne pas d'information sur la similarité.

3 méthodes : single, complete, average linkiage
single (= nearest neighbour methods) : accentue la similarité avec les éléments, le problème est qu'il surestime la similarité et 
produit un dendrogramme en forme de chaîne (chaining)
complete (=farthest neighbour method) à l'opposé extrême du single, il suraccentue les différences qui existe.
Average est celui qui est généralement utilisé, surtout en écologie, suivi du complete linkage method, le single n'est vraiment pas recommandé.

Commencer avec quelle approche une matrice de distance/dissimilarité: quel type ?
pourcentage ?
bcp de zéro ? si oui, on exclue euclédien, Manhattan et Canberra.
Chi² désaccentue l'abondance des espèces, s'il y a bcp ce n'est pas le meilleur choix.
Bray-Curtis : par défaut

vegdist() vegan
hclust() stats

Le dendrogramme se lit de haut en bas, l'axe vertical montre la similarité, en bas : similarité de zéro.
Dans l'exemple, les deux types de sites forme deux clusters. Cela signifie qu'il y a bien deux communautés de plantes différentes, car ils ont été séparé en deux clusters.
On voit aussi des différences parmi les sites d'un même type.

On peut calculer une correlation entre l'axe vertical (= cophanetique distance) et ma matrice de distance.
comm.coph <- cophoenetic(comm.bc.clust)
cor(comm.bc.dist, comm.coph)
[1] 0.9316768
Proche de 1, indique une bonne adaptation. On ne devrait pas utiliser seulement ce coefficient de correlation , car l'average method, produit généralement une correlation
plus grande qu'avec. Il ne faut pas se fier uniquement sur le coefficient de correlation, il faut aussi regarder le structure du dendrogramme. 
pvclust() : permet d'examiner statistiqument chaque branche. Produit une p-value pour chaque branche à l'aide du bootstrap.
Conseil de se référence au livre "Community Ecology"

Pour la variable environnemental $aspect, le premier type de site a un large gradient. Tandis que le 2ème type a une variation très faible.
Cela suggère que le site 1 est indifférent, tandis que le 2ème est plus sensible, peut-être que des variables y sont corrélés (t°c, hygro,...)



## non-hierarchical(disjoint,Divise) 
Meilleur pour les gros clusters
k-means
k est le nombre de cluster que l'on veut créer.
pam() produit un silouhette plot. McIntyre n'a quasiment jamais vue de plot silouhette en écologie. Car ce sont des mesures relatives.
Pour chaque cluster, on a la similarité de chaque élement (site).
Il est plus commun d'avoir une PCA. En comparant avec des boxplot une variable environnemental(siteinfo$aspect) par rapport au k-means généré (demopam\$clustering)
On s'apercçoit que k=5 était trop, plusieurs boxplot ont la même variation.

Comment choisir le meilleur k ?
Si on a deux types d'environnement distinct le mieux est de choisir k = 2. 
Si on n'est pas sûr 
comm.clust <- hclust(comm.bc.dist, method = "complete")
cutree(comm.clust, k = 2:5)
cutree va comparer les groupes en fonction du k. On cherche quelque chose de logique pas de variable.
En regardant, les clusters produit on peut trouver des outliers.
Le graphique k = 3 donne le même coefficient de correlation que n'importe quelle autre valeur de k



beta diversité
betadiver() vegan : calcul la diversité béta 
hclust() vegan pour réalisé un cluster hierarchique


## Note de fin 
Il est important de spécifier quelle type de méthode a été utilisé 






# Ordination contrainte et non-contrainte
https://www.youtube.com/watch?v=Wqa7_18jf5A

Permet sur un grand jeu de données espèces/sites d'essayer d'identifier les sites et espèces les plus influents qui explique
la plupart des tendances dans les données, ce qui donne des axe d'ordination qui résume les données selon les variables les 
plus importantes. On utilisera ces axes d'ordination dans une analyse de redondance contrainte  (RDA) pour examiner l'influence
des variables environnementales à partir d'un ensemble de données site par site sur la distribution des espèces dans les sites.

PCA et RDA sont deux forme d'ordination


##PCA : non contrainte
Non contrainte signifie qu'on ne regarde qu'un seul ensemble de données à la fois. Ces techniques ne tentent pas de définir une
relation entre des variables dépendantes et indépendantes.
https://r.qcbs.ca/workshop09/book-fr/le-significat-de-lordination-sans-contrainte.html
PCA réduit la "dimensionnalité" d'un grand ensemble de donnée de variable interreliées, mais ne supprime PAS les variables.
Résume les variables dans des axes

###L'ordination sans contraine peut être utilisé pour :
Evaluer les relations au sein d'un ensemble de variable
Trouver les éléments clés de variation au sein d'échantillons, de sites, d'espèces.
Réduire les dimensions d'un jeu de données multivariées sans perte importante d'information
Créer de nouvelles variables pour une utilisation dans des analyses ultérieures (comme la régression.)
Résume la redondance des données en identifiants les gradients  de variation dominants et en placant des entités d'échantillonnage
similaires dans des gradients de variations.
Resultant dans une description très économique des données.
Utilisé préliminairement dans le but de détecté des tendances parmi les variables. 
Pivote le nuage de points pour faire apparaître le maximum de variabilité, ce qui permet d'identifier les gradients les plus importants.
Généralement on utilise slmt 2 axes.

###Supposition : relation linéaire parmi les variables, càd relation linéaire entre les abondances/présences des espèces et l'environnement.
Malheureusement, on a plutôt souvent les espèces qui ont une courbe unimodale (= une seule courbe) avec le gradient de l'env. càd que l'abondance atteint un pic à un moment donnée. Il est possible d'avoir sur une partie de cette courbe une partie linéaire. 
Si ce n'est pas linéaire, la PCA n'est pas le meilleur choix. Si on a bcp de zéro, la PCA peut produire des fer à cheval, cela signifie que c'est mauvais, car on a violé l'indépendance des axes. Il n'y a plus de sens biologique à la représentation graphique.
On peut transformer les données avec un log() ou exp() ou utiliser Chord ou Hellenger. On ferait mieux d'essayer une autre forme d'ordination (CA par exemple).

###4 éléments dans le output d'une PCA
1) le % de variance (= mesure de la dispersion) expliqué par chaque PC
Il faut au minimum que 60% de la variance soit expliqué par les deux axes, si non, ce n'est pas très utile/informatif. (règle souvent violée)
2) species loadings : permet d'essayer d'identifier quelles espèces sont le plus influente dans l'ensemble des données
3) site score : détermine quel sites sont les plus influencants
4) ordination plot : biplot si 2 forme de data en même temps (site et sp)
Loadings (component loadings or factor loadings or weight)


###Interprétation 
Si une espèce est très abondante et particulièrement sur un site A et a une faible abondance sur un site B. C'est possible que PC1 soit très lié à l'abondance de cette sp
et PC2 à son absence, ce qui masque les autres espèces/
Les valeurs des loadings (positif et negatif) s'interprete seulement par colonne (PC), si une sp a un score très élevé à PC1 => très associé à sa présence (si >0) ou absence (<0). Si l'absence de cette sp est très associé à PC2
Si PC1 très associé à un site et PC2 très associé à un autre site
Biplot : on peut voir que certaines sp sont associé avec certains sites.
si les flèches (espèces) pointes vers la droite, cela indique que PC1 est associé positivement avec l'abondance avec ces sp. Une grande longueur indique une grande abondance (je suis pas sûr que ce soit correcte)
si elles point vers la gauche, cela suggère que PC1 est associé avec l'absence des ces sp (corrélation inverse).
Les sites éloignés de l'origine signifie qu'ils sont corrélés avec l'axe. Les points près du centre sont généralement mal représentés par le plan. 
On ne peut les interpréter avec confiance. Si deux points sont très corrélés, c'est bien d'essayer de voir si avec un autre axe s'ils sont toujours proches ou pas.
Les flèches avec des angles très proches signifie une grande corrélation, si proche de 180 correlation opposé, si angle droit pas de correlation.


### code
prcom() : scale = TRUE package vegan
princomp() package vegan plus de site que d'espèce
pca() : cor =TRUE package dsv
cor et scale font la même chose (soustrait la moyenne et divise par Standard Deviation)
Si les variables ont des unités différentes => standardiser => utiliser matrice de corrélation.
Dans mon cas, matrice sp vs site pas besoin, par contre pour matrice env vs site oui !
Si l'échelle des variables sont similaire => matrice covariance
Ce qui est recommandé dans en écologie c'est d'utiliser une matrice de correlation pour éviter que les sp abondantes influe sur le résultat.
Par contre utilisé une matrice de correlation  est une manière un peu brutale pour standardiser les données et peut étouffer la variance qu'on essaye d'examiner.
Ca reste ok
On peut aussi centrer les données (William disait que c'était important) en soustrayant les colonnes means.
prcomp(x, center = TRUE, scale = TRUE) 
matrice de correlation ou matrice de covariance ?
Svt => matrice de correlation recommandé en écologie

### Fin
Quand on a des bons axes PC, on peut utiliser ces axes comme des variables indépendantes dans d'autres analyses qui nous permet d'examiner l'influence des variables environnementales sur les espèces des sites, il faut donc utiliser une forme d'ordination contrainte comme la RDA.
Il est important de comprendre les limitations et les règles à respecté (assumptions)


##RDA : contrainte
Contrainte signifie que les patterns (tendance/motif) dans un ensemble de données site par espèce sont vraisemblablement
limité par des variable
Le but est d'identifier la relation entre un ensemble de variables réponse (matrice Y, décrivant généralement la composition en espèces des communautés)
et un ensemble de variable explicative (matrice X, contenant généralement des descripteurs envirronnementaux).
La RDA examine les relation que les variables env ont sur les axes PCA; sur ces ensembles de variables les plus influents.
Pas top si bcp de zéros comme PCA. On peut faire des transformation ou CCA.

### Utilisation
On peut faire d'abord une PCA qui trie un grand nombre de variable qui peuvent ensuite être utilisé par la RDA. La RDA est bonne pour détecter les relations env. <=> sp

### Code
rda() package vegan
rda(veg.center ~ env.scale, site) => les données ont été centré et réduite
créer un triplot : site, espèces, var. env.

### interpretation
Si le nuage de point des sites est étiré verticalement, on peut dire que les sites diffèrens avec les variables env. horizontal.
Si les sp ne semble pas fortement associé, cela signifie que les var env n'explique pas bcp la structuration des communautés

###L'ordination contraine peut être utilisé pour :
Permet de tester des hypothèses écologiques concernant les facteurs environnementaux qui déterminent la composition des communautés d'espèces.

### Assumptions (conditions)
les variables ont des relation linéaire avec les sites => transformer les données ou utiliser une autre méthode

L'ensemble de ces ordination permet d'essayer de déterminer les effets des espèces du sites et de l'env.

#CA : non contrainte
CA (correspondence analysis) appelé aussi Reciprocal Averaging
N'a pas besoin d'avoir des relations linéaires. Analogue à la PCA mais avec des relations unimodales.

# NMDS : non contrainte
https://www.youtube.com/watch?v=l3Rp3uiqFqw
réponse des sp aux var env. : unimodal


# CCA : contrainte
Unimodal analogue de la RDA (contrainte aussi)


# Canonical Correspondence Analysis
https://www.youtube.com/watch?v=raPTZtjyNos&t=1476s
Musique à associer 
https://youtu.be/Ug2kIzGOnI4?t=1774

PCA et RDA se font en deux étapes pour l'analyse des sp, sites et env.
Contrainte => la position des échantillons sont contraintes par les variables env
CCA : une des formes d'ordination contrainte les plus communément utilisé, à ne pas confondre avec CA (non contrainte)
réponse des sp aux var env. : unimodal

On commence avec une matrice de distance chi², ensuite on régresse par rapport aux var env afin d'obtenir des valeurs ajustées, puis on fait une regression pondéré où l'abondance total des sp par site est utilisé comme poids dans la régression pondéré. Après, on calcul la distance euclidienne de la matrice des données ajustées pour projeter les eigen values pour générer un triplot.

##Inconvénient 
accentue les sp rare et atténue les sp abondante

## Conditions
Données normalité multivarié (bien que la CCA gère bien les biais)
Si les var dépendante (=var réponse= abondance des sp ?) sont un peu biaisé c'est préférable de les transformer (racine carré ou log).
Cela empêche que la dominance de la contribution des variables.
Homogénité de la variance.
Unimodal (bell-shaped) réponse entre var env et composition des sp. Se rencontre lorsque l'on a des env propice et non propice aux sp.
Si on a autant de var. que de sites, l'ordination n'est plus contrainte, si on arrive a expliquer 100% de la variation des sp cela sera uniquement dû a un overfitted (surassociation/surcorrespondance) => faire ordination non contrainte en 1er pour identifier les var indépendantes les plus importantes et utiliser ensuite ces axes dans la CCA (~ PCA->RDA).


Il faut bien choisir les variables environnementales qui ne doivent pas être corrélés entres elles (ex : N, nitrite, nitrate). Note faire cor() pour savoir s'il y a une correlation entre les variables. 
Code Thomas and_corr2 <- cor(landscape2, use = "pairwise.complete.obs", method = c("pearson")) 
ggcorrplot(land_corr2, hc.order = TRUE, type = "lower", lab = TRUE)

## Interpretation
Inertie total (=variance=variation) qui peut être expliqué dans nos données.
"Constrained" variabilité expliqué par CCA, elle doit être élevé pour être informative. Variance ou "spread" du score des sp
Unconstrained variance non expliqué
Score de la répartition des espèces
Eigenvalues for constrained axes : montre la variance expliqué par les axes (CCA1~PC1).
Il faut prendre ce % et multiplié par la proportion d'inertie expliqué par l'inertie contrainte pour connaitre le % de variance expliqué par ces axes.

### Triplot
cca() vegan
rouge = sp
noir = site
bleu = var env
distance des objets (site et sp ?) indique leur similarité, les élements proche sont plus similaire entre eux.
L'angle des flèches montre la corrélation entre eux :petit angle = forte corrélation, 180° = corrélation négative, 90° pas de corrélation
La longueur indique l'importance de cette var env
La position des sites et sp par rapport aux flèches, indique les caractéristique otimal de chacune des sp
La flèche ayant la longueur la plus petite indique que c'est la variable la moins influentes 
Dans les notes elles montrent comment identifier les outmost (point extreme?)
Arch effect : pas commun en CCA mais en CA; indique association pauvre, que les axes ne sont pas indépendant entre eux.
Voir une courbe dans l'ordination signifie que c'est du caca
Si on relance une CCA sur notre CCA en ajoutant nos var + (rac[var]) et que le ratio entre l'inertie contrainte/non-cont augmente, c'est un signal qu'on a un arc effect et des facteurs explicatives qui n'ont pas été incluses dans notre analyse. On doit faire qqch à ce propos. Cela reste rare en CCA.
Exemple 3
Ajouter des var, devrait augmenter l'inertie contrainte, mais n'aide pas a expliquer l'ensemble des variations des données
On peut ajouter des variables qualitatives et avoir leur centroïdes sur le graphique .

























